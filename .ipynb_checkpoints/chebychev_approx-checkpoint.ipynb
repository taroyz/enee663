{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "pi = math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mynet(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super(Mynet, self).__init__()\n",
    "        self.n = n\n",
    "        self.fc1 = nn.Linear(n, 64, bias=False)\n",
    "        self.fc_last = nn.Linear(64, 1, bias=False)\n",
    "        self.alpha = Parameter(torch.Tensor(1))\n",
    "        \n",
    "    def forward(self, w):\n",
    "        a = tocosines(w, self.n)\n",
    "        out = self.fc1(a)\n",
    "        r = self.fc_last(out)\n",
    "        out = torch.cat((r, torch.ones(r.size(0),1)*self.alpha),1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tocosines(w, n):\n",
    "    '''\n",
    "    w: batch*1\n",
    "    '''\n",
    "    t = torch.arange(0, n, 1.0)\n",
    "    c = torch.ones(1, n)*2\n",
    "    c[0,0] = 1\n",
    "    out = torch.cos(torch.ger(w, t))*c\n",
    "    return out #batch*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_loss(w, out, wa, wb, tradeoff):\n",
    "    '''\n",
    "    w: batch * n\n",
    "    out: batch * 2\n",
    "    \n",
    "    '''\n",
    "    R = out[:,0].reshape(-1, 1)\n",
    "    alpha = out[:,1].reshape(-1, 1)\n",
    "    v = torch.cat((R*w/alpha-alpha, 1/alpha-R*w/alpha, -R), 1)\n",
    "    v = F.relu(v)\n",
    "    reg = reg_lambda(w, wa, wb, tradeoff)\n",
    "    loss = (torch.sum(v*reg) + torch.sum(alpha))/w.size(0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_lambda(w, wa, wb, tradeoff):\n",
    "    reg = torch.zeros(w.size(0), 3)\n",
    "    ind1 = ((wa < w < wb).nonzero())\n",
    "    reg[ind1, 0] = 1\n",
    "    reg[ind1, 1] = 1\n",
    "    reg[:, 2] = 1\n",
    "    return reg*tradeoff #batch*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D(w):\n",
    "    return w**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, W):\n",
    "        self.W = W\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.W)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        w = self.W[index]\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa = 0.01*pi\n",
    "wb = pi\n",
    "tradeoff = 20\n",
    "n = 50\n",
    "m = n*20\n",
    "W = np.linspace(0, pi, m).astype('float32')\n",
    "W = torch.from_numpy(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MyDataset(W),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mynet(n)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.9)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[400, 600], gamma=0.2)\n",
    "epochs = 1000\n",
    "\n",
    "model_best = model\n",
    "previous_loss = 10000\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    scheduler.step(epoch)\n",
    "    for i, w in enumerate(train_loader, 0):\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        out = model(w)\n",
    "        loss = customized_loss(w, out, wa, wb, tradeoff)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('epoch = %d, loss = %.6f' %(epoch, running_loss/i))\n",
    "    \n",
    "    if running_loss < previous_loss:\n",
    "        model_best = model\n",
    "    \n",
    "    previous_loss = running_loss\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result():\n",
    "    a =[]\n",
    "    for parameter in model_best.parameters():\n",
    "        a.append(parameter.data)\n",
    "    delta = a[0]\n",
    "    r = torch.mm(a[1].permute(1, 0), a[2].permute(1, 0))\n",
    "    return delta, r.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta, r = get_result()\n",
    "print(delta)\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    MyDataset(W),\n",
    "    batch_size=20, shuffle=True)\n",
    "with torch.no_grad():\n",
    "    for w in test_loader:\n",
    "        print(w)\n",
    "        out = model(w)\n",
    "        print (out)\n",
    "        R = out[:,0].reshape(-1, 1)\n",
    "        delta = out[:,1].reshape(-1, 1)\n",
    "        v = torch.cat((R-alpha**2, 1/(alpha**2)-R, R-delta, -R), 1)\n",
    "        print (v)\n",
    "        v = F.relu(v)\n",
    "        print(v)\n",
    "        reg = reg_lambda(w, ws, wp, tradeoff)\n",
    "        print (reg)\n",
    "        print (v*reg)\n",
    "        loss = (torch.sum(v*reg) + torch.sum(delta))/w.size(0)\n",
    "        loss = customized_loss(w, out, alpha, ws, wp, tradeoff)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_best, 'model_lowpass_attenuation.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.random.randn(4,1)\n",
    "w = np.random.randn(4,1)\n",
    "alpha = 2*np.ones((4,1))\n",
    "out = R*w/alpha\n",
    "print (R)\n",
    "print (w)\n",
    "print (alpha)\n",
    "print (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.18903622*-0.3123378/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.63223123*0.98311085/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
